"""
æ¨¡å—3ï¼šAIæ™ºèƒ½åˆ†æ

åŠŸèƒ½ï¼šä½¿ç”¨Claude APIå¯¹æ–°ä¸Šæ¦œäº§å“è¿›è¡Œæ·±åº¦åˆ†æ
"""

import os
import sys
import json
import argparse
from datetime import datetime
from typing import Dict, List, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°sys.path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.logger import setup_logger
from utils.data_storage import save_to_json, load_from_json
import anthropic


# é…ç½®
DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data")
LOG_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "logs")
LOG_FILE = os.path.join(LOG_DIR, "analyzer.log")

# ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs(DATA_DIR, exist_ok=True)

# åˆå§‹åŒ–æ—¥å¿—
logger = setup_logger('analyzer', LOG_FILE)

# å¯åŠ¨æ—¶ç«‹å³è®°å½•
logger.info("=" * 60)
logger.info("analyzer.py å¯åŠ¨")
logger.info(f"å·¥ä½œç›®å½•: {os.getcwd()}")
logger.info(f"è„šæœ¬ä½ç½®: {__file__}")
logger.info(f"æ•°æ®ç›®å½•: {DATA_DIR}")
logger.info(f"æ—¥å¿—æ–‡ä»¶: {LOG_FILE}")
logger.info("=" * 60)


def get_analysis_prompt(app: Dict) -> str:
    """
    ç”ŸæˆAIåˆ†æçš„Prompt

    Args:
        app: åº”ç”¨ä¿¡æ¯

    Returns:
        str: Promptæ–‡æœ¬
    """
    prompt = f"""è¯·å¯¹ä»¥ä¸‹æ–°ä¸Šæ¦œåº”ç”¨è¿›è¡Œæ·±åº¦åˆ†æï¼š

**åº”ç”¨ä¿¡æ¯**ï¼š
- åº”ç”¨åç§°ï¼š{app.get('name')}
- å¹³å°ï¼š{app.get('platform')}
- åˆ†ç±»ï¼š{app.get('category')}
- å¼€å‘è€…ï¼š{app.get('developer')}
- æ’åï¼š{app.get('rank')}
- å•†åº—é“¾æ¥ï¼š{app.get('store_url')}

è¯·æŒ‰ç…§ä»¥ä¸‹5ä¸ªç»´åº¦è¿›è¡Œåˆ†æï¼Œå¹¶ä»¥Markdownæ ¼å¼è¾“å‡ºï¼š

## 1. åŸºæœ¬ä¿¡æ¯åˆ†æ
- **äº§å“ä»‹ç»**ï¼šç”¨ä¸€å¥è¯ä»‹ç»è¿™æ˜¯ä¸€æ¬¾ä»€ä¹ˆäº§å“ï¼ˆæ ¸å¿ƒåŠŸèƒ½å’Œä»·å€¼ï¼‰
- äº§å“å‘å¸ƒæ—¶é—´å’Œä¸Šçº¿æ—¶é•¿
- ä¸»è¦å¸‚åœºå’Œåœ°åŒº
- å¼€å‘å•†èƒŒæ™¯å’Œå…¶ä»–äº§å“
- äº§å“æ•°æ®ï¼ˆè¯„åˆ†ã€è¯„è®ºæ•°ç­‰å¯æ¨æµ‹çš„ä¿¡æ¯ï¼‰

## 2. æŠ•æ”¾ç´ æåˆ†æ
- ä¸»è¦æ¨å¹¿æ¸ é“åˆ†æ
- æ¨å¹¿ç´ ææ–¹å‘ï¼ˆè§†é¢‘ã€å›¾ç‰‡ã€æ–‡æ¡ˆé£æ ¼ï¼‰
- ç›®æ ‡ç”¨æˆ·ç”»åƒ

## 3. äº§å“åŠŸèƒ½åˆ†æ
- æ ¸å¿ƒåŠŸèƒ½åˆ—è¡¨
- åˆ›æ–°ç‚¹å’Œå·®å¼‚åŒ–ä¼˜åŠ¿
- ç”¨æˆ·ä½“éªŒäº®ç‚¹

## 4. ç”¨æˆ·è¯„ä»·åˆ†æ
- æ­£é¢è¯„ä»·çš„å…³é”®ç‚¹ï¼ˆç”¨æˆ·å–œçˆ±çš„åŠŸèƒ½ï¼‰
- è´Ÿé¢è¯„ä»·çš„å¸¸è§é—®é¢˜
- æ”¹è¿›å»ºè®®

## 5. æ€è€ƒä¸æ€»ç»“
- æ•´ä½“è¯„ä¼°ï¼ˆä¼˜åŠ£åŠ¿æ€»ç»“ï¼‰
- æˆåŠŸå› ç´ åˆ†æï¼ˆä¸ºä»€ä¹ˆèƒ½å¿«é€Ÿä¸Šæ¦œï¼‰
- å¯å€Ÿé‰´ä¹‹å¤„ï¼ˆå¯¹ç«å“æˆ–è‡ªå·±äº§å“çš„å¯å‘ï¼‰
- å¸‚åœºæœºä¼šæ´å¯Ÿ

**æ³¨æ„**ï¼š
1. äº§å“ä»‹ç»å¿…é¡»ç®€æ´æ˜äº†ï¼Œä¸€å¥è¯æ¦‚æ‹¬äº§å“çš„æ ¸å¿ƒä»·å€¼å’Œå®šä½
2. è¯·åŸºäºåº”ç”¨åç§°ã€åˆ†ç±»å’Œå¼€å‘è€…ä¿¡æ¯è¿›è¡Œåˆç†æ¨æµ‹
3. ä¿æŒåˆ†æç®€æ´ï¼Œæ¯ä¸ªç»´åº¦æ§åˆ¶åœ¨200å­—ä»¥å†…
4. ä½¿ç”¨Markdownæ ¼å¼ï¼Œæ¸…æ™°åˆ†æ®µ
5. çªå‡ºå…³é”®ä¿¡æ¯ï¼Œä½¿ç”¨åˆ—è¡¨å’ŒåŠ ç²—
"""
    return prompt


def analyze_app(app: Dict) -> Optional[Dict]:
    """
    ä½¿ç”¨Claude APIåˆ†æå•ä¸ªåº”ç”¨

    Args:
        app: åº”ç”¨ä¿¡æ¯

    Returns:
        Dict: åˆ†æç»“æœï¼ŒåŒ…å«markdownå’Œç»“æ„åŒ–æ•°æ®
    """
    try:
        logger.info(f"=" * 60)
        logger.info(f"å¼€å§‹åˆ†æåº”ç”¨: {app.get('name')}")
        logger.info(f"  App ID: {app.get('app_id')}")
        logger.info(f"  Platform: {app.get('platform')}")
        logger.info(f"  Category: {app.get('category')}")
        logger.info(f"=" * 60)

        # åˆå§‹åŒ–Anthropicå®¢æˆ·ç«¯
        logger.info("åˆå§‹åŒ–Anthropicå®¢æˆ·ç«¯...")
        try:
            client = anthropic.Anthropic()
            logger.info("âœ“ å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âœ— å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

        # ç”Ÿæˆprompt
        logger.info("ç”Ÿæˆåˆ†æPrompt...")
        prompt = get_analysis_prompt(app)
        logger.info(f"âœ“ Prompté•¿åº¦: {len(prompt)} å­—ç¬¦")

        # è°ƒç”¨Claude API
        logger.info("è°ƒç”¨Claude API...")
        logger.info(f"  æ¨¡å‹: claude-sonnet-4-5-20250929")
        logger.info(f"  æœ€å¤§Token: 4000")

        try:
            message = client.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=4000,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            logger.info("âœ“ APIè°ƒç”¨æˆåŠŸ")
        except Exception as e:
            logger.error(f"âœ— APIè°ƒç”¨å¤±è´¥: {e}")
            raise

        # æå–åˆ†æç»“æœ
        analysis_markdown = message.content[0].text
        logger.info(f"âœ“ è·å¾—åˆ†æç»“æœï¼Œé•¿åº¦: {len(analysis_markdown)} å­—ç¬¦")

        # Tokenä½¿ç”¨ç»Ÿè®¡
        logger.info(f"Tokenä½¿ç”¨:")
        logger.info(f"  è¾“å…¥: {message.usage.input_tokens}")
        logger.info(f"  è¾“å‡º: {message.usage.output_tokens}")
        logger.info(f"  æ€»è®¡: {message.usage.input_tokens + message.usage.output_tokens}")

        # æ„å»ºç»“æœ
        result = {
            "app_id": app.get('app_id'),
            "name": app.get('name'),
            "platform": app.get('platform'),
            "category": app.get('category'),
            "developer": app.get('developer'),
            "rank": app.get('rank'),
            "store_url": app.get('store_url'),
            "icon_url": app.get('icon_url'),
            "analysis_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "analysis_markdown": analysis_markdown,
            "tokens_used": {
                "input": message.usage.input_tokens,
                "output": message.usage.output_tokens
            }
        }

        logger.info(f"âœ“ åˆ†æå®Œæˆ: {app.get('name')}")
        return result

    except Exception as e:
        logger.error(f"=" * 60)
        logger.error(f"âœ— åˆ†æåº”ç”¨å¤±è´¥: {app.get('name')}")
        logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        logger.error(f"=" * 60)
        import traceback
        logger.error(traceback.format_exc())
        return None


def save_analysis_result(app_id: str, result: Dict, date_str: str):
    """
    ä¿å­˜åˆ†æç»“æœ

    Args:
        app_id: åº”ç”¨ID
        result: åˆ†æç»“æœ
        date_str: æ—¥æœŸå­—ç¬¦ä¸²
    """
    # ä¿å­˜JSONæ ¼å¼
    analysis_dir = os.path.join(DATA_DIR, "analysis", date_str)
    os.makedirs(analysis_dir, exist_ok=True)

    # ä¿å­˜JSON
    json_path = os.path.join(analysis_dir, f"{app_id}.json")
    save_to_json(result, json_path)
    logger.info(f"å·²ä¿å­˜JSON: {json_path}")

    # ä¿å­˜Markdownæ ¼å¼
    md_path = os.path.join(analysis_dir, f"{app_id}.md")
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(f"# {result['name']}\n\n")
        f.write(f"**å¹³å°**: {result['platform']} | ")
        f.write(f"**åˆ†ç±»**: {result['category']} | ")
        f.write(f"**æ’å**: #{result['rank']}\n\n")
        f.write(f"**å¼€å‘è€…**: {result['developer']}\n\n")
        f.write(f"**å•†åº—é“¾æ¥**: {result['store_url']}\n\n")
        f.write(f"**åˆ†ææ—¶é—´**: {result['analysis_date']}\n\n")
        f.write("---\n\n")
        f.write(result['analysis_markdown'])

    logger.info(f"å·²ä¿å­˜Markdown: {md_path}")




def find_app_in_new_apps(app_id: str, platform: str) -> Optional[Dict]:
    """
    åœ¨new_appsç›®å½•ä¸­æŸ¥æ‰¾æŒ‡å®šåº”ç”¨çš„å®Œæ•´ä¿¡æ¯

    Args:
        app_id: åº”ç”¨ID
        platform: å¹³å°

    Returns:
        Dict: åº”ç”¨å®Œæ•´ä¿¡æ¯ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
    """
    new_apps_dir = os.path.join(DATA_DIR, "new_apps")

    if not os.path.exists(new_apps_dir):
        return None

    # éå†new_appsç›®å½•ä¸‹çš„JSONæ–‡ä»¶
    for filename in sorted(os.listdir(new_apps_dir), reverse=True):
        if not filename.endswith('.json'):
            continue

        file_path = os.path.join(new_apps_dir, filename)

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            new_apps = data.get('new_apps', [])

            for app in new_apps:
                if app.get('app_id') == app_id and app.get('platform') == platform:
                    logger.info(f"æ‰¾åˆ°åº”ç”¨ä¿¡æ¯: {filename}")
                    return app

        except Exception as e:
            logger.error(f"è¯»å–æ–‡ä»¶å¤±è´¥ {filename}: {e}")

    return None






def main():
    """ä¸»å‡½æ•° - åªæ”¯æŒå•ä¸ªåº”ç”¨åˆ†æ"""
    parser = argparse.ArgumentParser(description='AIæ™ºèƒ½åˆ†ææ¨¡å— - å•åº”ç”¨åˆ†æ')
    parser.add_argument('--app-id', type=str, required=True, help='åº”ç”¨IDï¼ˆå¿…éœ€ï¼‰')
    parser.add_argument('--platform', type=str, required=True, help='å¹³å°åç§°ï¼ˆå¿…éœ€ï¼‰')
    parser.add_argument('--date', type=str, help='æŒ‡å®šæ—¥æœŸï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»Šå¤©ï¼‰')

    args = parser.parse_args()

    logger.info("=" * 60)
    logger.info("ğŸ¤– AIæ™ºèƒ½åˆ†æ - å•åº”ç”¨æ¨¡å¼")
    logger.info("=" * 60)
    logger.info(f"App ID: {args.app_id}")
    logger.info(f"Platform: {args.platform}")
    logger.info("=" * 60)

    date_str = args.date or datetime.now().strftime("%Y-%m-%d")

    # ä»new_appsç›®å½•æŸ¥æ‰¾åº”ç”¨çš„å®Œæ•´ä¿¡æ¯
    app = find_app_in_new_apps(args.app_id, args.platform)

    if not app:
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œåˆ›å»ºä¸´æ—¶åº”ç”¨å¯¹è±¡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        logger.warning(f"âš ï¸  æœªåœ¨new_appsç›®å½•æ‰¾åˆ°åº”ç”¨ä¿¡æ¯ï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯")
        app = {
            'app_id': args.app_id,
            'name': args.app_id.split('.')[-1].title(),
            'platform': args.platform,
            'category': 'Unknown',
            'developer': 'Unknown',
            'rank': 0,
            'store_url': '',
            'icon_url': ''
        }
    else:
        logger.info(f"âœ“ æ‰¾åˆ°åº”ç”¨å®Œæ•´ä¿¡æ¯")
        logger.info(f"  åç§°: {app.get('name')}")
        logger.info(f"  å¼€å‘è€…: {app.get('developer')}")
        logger.info(f"  åˆ†ç±»: {app.get('category')}")

    # æ‰§è¡Œåˆ†æ
    result = analyze_app(app)

    if result:
        save_analysis_result(args.app_id, result, date_str)
        logger.info("=" * 60)
        logger.info(f"âœ“ åˆ†ææˆåŠŸ: {app.get('name')}")
        logger.info(f"  ä¿å­˜ä½ç½®: data/analysis/{date_str}/{args.app_id}.json")
        logger.info("=" * 60)
        sys.exit(0)
    else:
        logger.error("=" * 60)
        logger.error(f"âœ— åˆ†æå¤±è´¥: {app.get('name')}")
        logger.error("=" * 60)
        sys.exit(1)


if __name__ == "__main__":
    main()
